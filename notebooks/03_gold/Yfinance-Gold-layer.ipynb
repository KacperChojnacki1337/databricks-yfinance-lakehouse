{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08289bae-5e13-4184-ab61-a60ddb1d9395",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import yaml\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import IntegerType, FloatType\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.window import Window\n",
    "import os\n",
    "\n",
    "# --- 1. Environment Configuration and Config Loading ---\n",
    "\n",
    "# Environment variable (assumed to be set by Job or widget)\n",
    "try:\n",
    "    ENV = dbutils.widgets.get(\"env_name\")\n",
    "except Exception:\n",
    "    ENV = 'TEST' # Default environment\n",
    "\n",
    "# Load YAML Configuration\n",
    "try:\n",
    "    # Adjust '../../config/config.yaml' path to the actual location if needed\n",
    "    with open('../../config/config.yaml', 'r') as file:\n",
    "        full_config = yaml.safe_load(file)\n",
    "except FileNotFoundError:\n",
    "    print(\"ERROR: 'config.yaml' file not found! Check the path.\")\n",
    "    raise\n",
    "\n",
    "CFG = full_config.get(ENV)\n",
    "if not CFG:\n",
    "    raise ValueError(f\"Configuration not found for environment: {ENV} in YAML file.\")\n",
    "\n",
    "catalog_name = CFG['catalog_name']\n",
    "schema_name = CFG['schema_name']\n",
    "volume_name = CFG['volume_name']\n",
    "\n",
    "# Precision constant used in the Silver layer\n",
    "PRECISION = 4 \n",
    "\n",
    "# --- 2. Data Path Definition ---\n",
    "\n",
    "silver_table_path = f\"/Volumes/{catalog_name}/{schema_name}/{volume_name}/yfinance_silver_data\"\n",
    "gold_table_path = f\"/Volumes/{catalog_name}/{schema_name}/{volume_name}/yfinance_gold_data\"\n",
    "\n",
    "print(f\"Source Path (Silver): {silver_table_path}\")\n",
    "print(f\"Target Path (Gold): {gold_table_path}\")\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f28b30d6-4edb-40d3-b594-27c4952d465b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- 3. Load Data from Silver Layer ---\n",
    "\n",
    "try:\n",
    "    # Always read data from the persistent layer to ensure pipeline independence\n",
    "    df_silver = (\n",
    "        spark.read.format(\"delta\")\n",
    "        .load(silver_table_path)\n",
    "    )\n",
    "    print(f\"Successfully loaded data from the Silver layer. Row count: {df_silver.count()}\")\n",
    "except Exception as e:\n",
    "    print(f\"CRITICAL ERROR: Failed to load data from Silver. Gold pipeline cannot proceed. Details: {e}\")\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b762e949-6624-4123-b4c4-8403530e0f95",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Define the monthly aggregation\n",
    "df_gold = (\n",
    "    df_silver\n",
    "    .groupBy(\"Ticket\", \"Year\", \"Month\")\n",
    "    .agg(\n",
    "        # Price Metrics\n",
    "        F.max(F.col(\"Close\")).alias(\"Monthly_Max_Close\"),\n",
    "        F.min(F.col(\"Close\")).alias(\"Monthly_Min_Close\"),\n",
    "        \n",
    "        # Volume Metrics\n",
    "        F.round(F.avg(F.col(\"Volume\")), 0).cast(IntegerType()).alias(\"Monthly_Avg_Volume\"),\n",
    "        F.sum(F.col(\"Volume\")).alias(\"Monthly_Total_Volume\"),\n",
    "        \n",
    "        # Return Metrics (using the predefined PRECISION)\n",
    "        F.round(F.avg(F.col(\"Daily_Return_Pct\")), PRECISION).cast(FloatType()).alias(\"Monthly_Avg_Daily_Return_Pct\")\n",
    "    )\n",
    "    .orderBy(\"Ticket\", \"Year\", \"Month\")\n",
    ")\n",
    "\n",
    "print(\"Successfully created the aggregated DataFrame for the Gold layer (Monthly Aggregation).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72801ddb-c134-4469-be6a-413ef13cb645",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- 5. Write Data to the Gold Layer ---\n",
    "\n",
    "# Ensure the directory exists (idempotent operation)\n",
    "try:\n",
    "    dbutils.fs.mkdirs(gold_table_path)\n",
    "except Exception:\n",
    "    pass # Directory already exists\n",
    "\n",
    "# Write in 'overwrite' mode with partitioning\n",
    "(\n",
    "    df_gold.write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .partitionBy(\"Ticket\", \"Year\") # Partitioning for optimized analytical queries\n",
    "    .option(\"overwriteSchema\", \"true\")\n",
    "    .save(gold_table_path)\n",
    ")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "print(f\"âœ… SUCCESS: Gold layer data saved to: {gold_table_path}\")\n",
    "print(\"Gold pipeline finished.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Yfinance-Gold-layer",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
