{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c14184f-e0b8-46e9-b3b6-efed0508a663",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from io import StringIO\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# --- TEST IMPORTS ---\n",
    "# Adding the project root folder to sys.path so that imports work\n",
    "sys.path.append(os.path.abspath('../../'))\n",
    "from tests.meta_tests import verify_metadata_batch\n",
    "\n",
    "FILE_ID = \"1alcsznO40FQOQg68t2wXC0gPb09DbXvP\" \n",
    "TARGET_TABLE = \"workspace.google_drive.gpw_data\"\n",
    "URL = f\"https://docs.google.com/spreadsheets/d/{FILE_ID}/export?format=csv\"\n",
    "\n",
    "print(f\"--- STARTING METADATA SYNC ---\")\n",
    "\n",
    "try:\n",
    "    # 1. Fetch data from Google Drive with timeout\n",
    "    response = requests.get(URL, timeout=30)\n",
    "    \n",
    "    # Retry with alternative URL if the first attempt fails\n",
    "    if response.status_code != 200:\n",
    "        URL_ALT = f\"https://docs.google.com/uc?export=download&id={FILE_ID}\"\n",
    "        response = requests.get(URL_ALT, timeout=30)\n",
    "        \n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Download failed. Status: {response.status_code}\")\n",
    "\n",
    "    # 2. Basic content validation (ensure we didn't receive an HTML login page)\n",
    "    if \"<html\" in response.text.lower():\n",
    "        raise Exception(\"Received HTML instead of CSV. Check Drive sharing permissions.\")\n",
    "\n",
    "    # 3. Load into Pandas for initial sanity check\n",
    "    pdf = pd.read_csv(StringIO(response.text))\n",
    "    \n",
    "    if pdf.empty:\n",
    "        raise Exception(\"The downloaded CSV is empty. Preventing table overwrite.\")\n",
    "\n",
    "    print(f\"Successfully fetched {len(pdf)} rows.\")\n",
    "\n",
    "    # 4. Convert to Spark DataFrame and normalize column names\n",
    "    spark_df = spark.createDataFrame(pdf)\n",
    "    spark_df = spark_df.toDF(*[c.lower().replace(\" \", \"_\") for c in spark_df.columns])\n",
    "\n",
    "    # 5. Execute Data Quality Validation from external module\n",
    "    is_valid, msg = verify_metadata_batch(spark_df)\n",
    "\n",
    "    if is_valid:\n",
    "        print(f\"✅ Metadata validation passed. Updating control table: {TARGET_TABLE}\")\n",
    "        \n",
    "        # 6. Save data to Delta Lake (Atomic Overwrite)\n",
    "        # Dropping and recreating ensures the schema is refreshed if Google Drive columns changed\n",
    "        spark.sql(f\"DROP TABLE IF EXISTS {TARGET_TABLE}\")\n",
    "        spark_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(TARGET_TABLE)\n",
    "        \n",
    "        print(f\"✅ SUCCESS: Table {TARGET_TABLE} synchronized.\")\n",
    "    else:\n",
    "        # Halt execution if Data Quality requirements are not met\n",
    "        error_msg = f\"DATA VALIDATION FAILED: {msg}. Aborting process to protect downstream pipeline.\"\n",
    "        print(f\"❌ {error_msg}\")\n",
    "        raise Exception(error_msg)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ ERROR: {str(e)}\")\n",
    "    # Re-raising ensures the Databricks Workflow captures the failure\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "00_METADATA_SYNC",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
